---
title: "REPORT OF DATA-SCIENCE CLASS"
author: "Santiago Pulido Guerrero"
date: "23-11-2020"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: true
    toc_depth: 3
    #code_folding: hide
--- -g 

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

## CHAPTER 2: INTRO TO THE TIDYVERSE
#CHALLENGE 1: ANALYSIS OF SALES BY PLACE AND YEAR

Last compiled: `r Sys.Date()`

1) Analysis of the sales by location and by year and location considering the 12 states of Germany and using bar plots.

```{r}
# Data Science at TUHH ------------------------------------------------------
# SALES ANALYSIS ----

# 1.0 Load libraries ----
library(ggplot2)
library(tidyverse)
library(readxl)
library("writexl")

# 2.0 Importing Files ----

bikes_data <- read_excel(path = "D:/data-science/DS_Data-Science/00_data/01_bike_sales/01_raw_data/bikes.xlsx",sheet = NULL)
bikeshops_data <- read_excel(path = "D:/data-science/DS_Data-Science/00_data/01_bike_sales/01_raw_data/bikeshops.xlsx",sheet = NULL)
orderlines_data <- read_excel(path = "D:/data-science/DS_Data-Science/00_data/01_bike_sales/01_raw_data/orderlines.xlsx",sheet = NULL)

# 3.0 Joining Data ----

bikes_total_dataA = left_join(orderlines_data,bikes_data, by = c("product.id"="bike.id"))
bikes_total_dataB = left_join(orderlines_data,bikeshops_data, by = c("customer.id"="bikeshop.id"))
bike_orderlines_wrangled = left_join(bikes_total_dataA,bikes_total_dataB,by = NULL)

# 5.0 Wrangling Data ----

bike_orderlines_wrangled_tbl <- bike_orderlines_wrangled %>% separate(col = 'location',into = c("City","State"),sep = ",")%>% 
mutate(total.price = price*quantity)%>%
select(order.id, contains("order"),contains("model"),contains("location"),price, quantity, total.price,everything()) %>%
rename(bikeshop = name) %>%  set_names(names(.) %>% str_replace_all("\\.", "_"))


# 6.0 Business Insights ----

# 6.1 States with the highest revenue ----

# Step 1 - Manipulate

sales_by_loc_tbl <- bike_orderlines_wrangled_tbl %>% separate(col = "order_date",into = c("order_year","order_month","order_day"),sep = "-") %>% 
  group_by(State) %>%  summarize(total_sales = sum(total_price))%>%
  mutate(sales_in_euros = scales::dollar(total_sales, big.mark = ".",decimal.mark = ",",prefix = "",suffix = "\u20ac"))

sales_by_loc_year_tbl <- bike_orderlines_wrangled_tbl %>% separate(col = "order_date",into = c("order_year","order_month","order_day"),sep = "-") %>% 
  group_by(order_year,State) %>%  summarize(total_sales = sum(total_price))%>%
  mutate(sales_in_euros = scales::dollar(total_sales, big.mark = ".",decimal.mark = ",",prefix = "",suffix = "\u20ac"))
  
# Step 2 - Visualize

sales_by_loc_tbl %>% ggplot(aes(x = State,y = total_sales))+ theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
geom_col(fill = "#2DC6D6") + geom_label(aes(label = sales_in_euros)) + geom_smooth(method = "lm", se = FALSE) +
scale_y_continuous(labels = scales::dollar_format(big.mark = ".",decimal.mark = ",",prefix = "",suffix = "\u20ac")) +  
labs(
    title    = "Revenue by state",
    subtitle = "Highest revenues",
    x = "", # Override defaults for x and y
    y = "Revenue in euros \u20ac"
  )
ggsave("sales_by_loc_tbl.png", height = 30, width = 35,units = "cm")

# 6.2 Sales by Year and Category 2 ----

# Step 2 - Visualize

sales_by_loc_year_tbl %>% ggplot(aes(x = order_year,y = total_sales, fill = State))+ theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  geom_col() + facet_wrap(~ State) + scale_y_continuous(labels = scales::dollar_format(big.mark = ".",decimal.mark = ",",prefix = "",suffix = "\u20ac")) +  
  labs(
    title    = "Revenue by state",
    subtitle = "Highest revenues",
    fill = "Sales by states"
  )
ggsave("sales_by_loc_year_tbl.png", height = 35, width = 35,units = "cm")

# 7.0 Writing Files ----

#install.packages("writexl")
library("writexl")
# 7.1 XLSX ----
sales_by_loc_tbl %>% write_xlsx("D:/data-science/DS_Data-Science/00_data/01_bike_sales/02_wrangled_data/sales_by_loc.xlsx")
sales_by_loc_year_tbl %>% write_xlsx("D:/data-science/DS_Data-Science/00_data/01_bike_sales/02_wrangled_data/sales_by_loc_year.xlsx")
# 7.2 CSV ----
sales_by_loc_tbl %>% write_csv("D:/data-science/DS_Data-Science/00_data/01_bike_sales/02_wrangled_data/sales_by_loc.csv")
sales_by_loc_year_tbl %>% write_csv("D:/data-science/DS_Data-Science/00_data/01_bike_sales/02_wrangled_data/sales_by_loc_year.csv")
# 7.3 RDS ----
sales_by_loc_tbl %>% write_rds("D:/data-science/DS_Data-Science/00_data/01_bike_sales/02_wrangled_data/sales_by_loc.rds")
sales_by_loc_year_tbl %>% write_rds("D:/data-science/DS_Data-Science/00_data/01_bike_sales/02_wrangled_data/sales_by_loc_year.rds")
```

# CHALLENGE 2: 
## API data acquisition
For the API data acquisition challenge, the OPENWEATHERMAP provider was selected. The code used was

```{r,message=FALSE}
## CHALLENGE 2.0
# SECTION 1.0
# 1.0 LIBRARIES ----

library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing
library(glue)      # String interpolation
library(httr)      # API GET function
library(rstudioapi) # Securing credentials

# 1.2 request data from source

city_name <- list("Hamburg","Tokio","Bogota")
Api_key <- "d7736dd80cd838bf45d50b696167e9f5"
city_wheather = list()
x = c()
n = 0;
for (i in city_name){
n = n + 1
resp <- GET(glue("https://api.openweathermap.org/data/2.5/weather?q={i}&units=metric&appid={Api_key}"));
x[n] <- content(resp, as = "text")

}

```

```{r}
# 1.3 Print data from the Source
map(x,print);

# API Key protection

alphavantage_api_url <- "https://www.alphavantage.co/query"
ticker               <- "WDI.DE"

GET(alphavantage_api_url, query = list('function' = "GLOBAL_QUOTE",
                                       symbol     = ticker,
                                       apikey     = Sys.getenv("MyPersonalToken"))
)

```

## Scraping information

The selected competitor website was https://www.rosebikes.de/. The code produced is

```{r}

# SECTION 2.0

# 2.0 LIBRARIES

library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing
library(httr)      # include functions 
library(rstudioapi)# Securing credentials
# 2.1 Collection of products features

url_home <- "https://www.rosebikes.de/fahrrÃ¤der/mtb"

xopen(url_home)

html_home <- read_html(url_home)

mtb_bikes_family <- html_home %>%
  
  html_nodes(css = ".catalog-category-bikes__title-text") %>% html_text() %>% 
  
  enframe(name = "position",value = "Family_class") %>% mutate( family_class = str_glue("#MTB"))
  
  
mtb_bikes_price <- html_home  %>% html_nodes(css = ".catalog-category-bikes__price-title") %>% html_text() %>% 
  
  enframe(name = "position",value = "Price") 

mtb_bikes_tbl <- mtb_bikes_family %>% left_join(mtb_bikes_price, by = c("position"="position"))

# Printing the data

mtb_bikes_tbl %>% print()

alphavantage_api_url <- "https://www.alphavantage.co/query"
ticker               <- "WDI.DE"

GET(alphavantage_api_url, query = list('function' = "GLOBAL_QUOTE",
                                       symbol     = ticker,
                                       apikey     = Sys.getenv("MyPersonalToken"))
)

```
# CHALLENGE 3

The top ten companies with the most patents

```{r}

# 1.0 libraries
library(vroom)
library(readxl)
library("writexl")
library(tidyr)
library(purrr)
library("stringr") 
library(dplyr)
library(data.table)
# Tidyverse
library(tidyverse)

# 2.0 import data

col_assignee <- list(
  id = col_character(),
  type = col_character(),
  name_first = col_character(),
  name_last = col_character(),
  organization = col_character()
)

col_patent_assignee <- list(
  patent_id = col_character(),
  assignee_id = col_character(),
  location_id = col_character()
  
)

assignee_tbl <- vroom(
  
  file = "assignee.tsv",
  delim      = "\t", 
  col_types  = list(name_first = col_skip(),name_last = col_skip()),
  na         = c("", "NA", "NULL")
  
)

patent_assignee_tbl <- vroom(
  
  file = "patent_assignee.tsv",
  delim      = "\t", 
  col_types  =  col_patent_assignee,
  na         = c("", "NA", "NULL")
  
)

class(assignee_tbl)

setDT(assignee_tbl)

class(patent_assignee_tbl)

setDT(patent_assignee_tbl)

# 3.0 Data Wranggling

patent_assignee_tbl <- patent_assignee_tbl %>% select(patent_id, assignee_id, location_id) %>% rename(pat_id = patent_id,
                                                                                                      id = assignee_id,
                                                                                                      Loc_id = location_id) 

complete_patent_tbl <- merge(x = patent_assignee_tbl, y = assignee_tbl, by = "id",all.x = TRUE, all.y = TRUE)


# filtering

# Categories

# 2 US Company or Corporation
# 4 US individual
# 6 US Federal government
# 8 US County Government
# 9 US State Government

filtered_data <- complete_patent_tbl %>% select(type,organization) %>% filter((type %% 2 == 0)|(type == 9))

unique_values <- filtered_data %>% distinct(organization) %>% view()

num_patents_by_co <- filtered_data %>% group_by(organization) %>% count() %>% arrange(desc(n)) %>% view()

num_patents_by_co %>% head(n=10)



```



Last compiled: `r Sys.Date()`

I'm writing this tutorial going from the top down. And, this is how it will be printed. So, notice the second post is second in the list. If you want your most recent post to be at the top, then make a new post starting at the top. If you want the oldest first, do, then keep adding to the bottom

# Adding R stuff

So far this is just a blog where you can write in plain text and serve your writing to a webpage. One of the main purposes of this lab journal is to record your progress learning R. The reason I am asking you to use this process is because you can both make a website, and a lab journal, and learn R all in R-studio. This makes everything really convenient and in the same place. 

So, let's say you are learning how to make a histogram in R. For example, maybe you want to sample 100 numbers from a normal distribution with mean = 0, and standard deviation = 1, and then you want to plot a histogram. You can do this right here by using an r code block, like this:

```{r}
samples <- rnorm(100, mean=0, sd=1)
hist(samples)
```

When you knit this R Markdown document, you will see that the histogram is printed to the page, along with the R code. This document can be set up to hide the R code in the webpage, just delete the comment (hashtag) from the cold folding option in the yaml header up top. For purposes of letting yourself see the code, and me see the code, best to keep it the way that it is. You'll learn that all of these things and more can be customized in each R code block.